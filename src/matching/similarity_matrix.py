#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å­¦ç”Ÿ-é¡¹ç›®ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—ç³»ç»Ÿ
è®¡ç®—æ‰€æœ‰å­¦ç”Ÿä¸æ‰€æœ‰é¡¹ç›®çš„äº¤å‰ç›¸ä¼¼åº¦åˆ†æ•°
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import networkx as nx
from collections import defaultdict, Counter

@dataclass
class SimilarityResult:
    """ç›¸ä¼¼åº¦ç»“æœ"""
    student_id: str
    project_id: str
    similarity_score: float
    skill_match: float
    course_match: float
    technology_match: float
    major_match: float
    total_entities: int
    matched_entities: int

class StudentProjectSimilarityMatrix:
    """å­¦ç”Ÿ-é¡¹ç›®ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—å™¨"""
    
    def __init__(self, output_dir: str = "similarity_results"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.projects = {}
        self.students = {}
        self.similarity_matrix = {}
        self.detailed_results = []
        
        # å®ä½“ç±»å‹æƒé‡
        self.entity_weights = {
            'SKILL': 0.4,
            'TECHNOLOGY': 0.3,
            'COURSE': 0.2,
            'MAJOR': 0.1
        }
        
    def load_kg_data(self):
        """åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®"""
        print("ğŸ“Š åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®...")
        
        # åŠ è½½é¡¹ç›®æ•°æ®
        self._load_projects()
        
        # åŠ è½½å­¦ç”Ÿæ•°æ®
        self._load_students()
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.projects)} ä¸ªé¡¹ç›®, {len(self.students)} ä¸ªå­¦ç”Ÿ")
        
    def _load_projects(self):
        """åŠ è½½é¡¹ç›®çŸ¥è¯†å›¾è°±æ•°æ®"""
        project_kg_dir = "individual_kg/projects"
        if not os.path.exists(project_kg_dir):
            print(f"âŒ é¡¹ç›®KGç›®å½•ä¸å­˜åœ¨: {project_kg_dir}")
            return
            
        for file in os.listdir(project_kg_dir):
            if file.endswith("_entities.json"):
                project_id = file.replace("_entities.json", "")
                try:
                    with open(os.path.join(project_kg_dir, file), 'r', encoding='utf-8') as f:
                        entities = json.load(f)
                    
                    # ç»Ÿè®¡å®ä½“ç±»å‹
                    entity_counts = defaultdict(int)
                    for entity in entities:
                        entity_type = entity.get('entity_type', 'UNKNOWN')
                        entity_counts[entity_type] += 1
                    
                    self.projects[project_id] = {
                        'entities': entities,
                        'entity_counts': dict(entity_counts),
                        'total_entities': len(entities)
                    }
                    
                except Exception as e:
                    print(f"  âš ï¸ åŠ è½½é¡¹ç›®å¤±è´¥ {file}: {e}")
    
    def _load_students(self):
        """åŠ è½½å­¦ç”ŸçŸ¥è¯†å›¾è°±æ•°æ®"""
        student_kg_dir = "individual_kg/students"
        if not os.path.exists(student_kg_dir):
            print(f"âŒ å­¦ç”ŸKGç›®å½•ä¸å­˜åœ¨: {student_kg_dir}")
            return
            
        for file in os.listdir(student_kg_dir):
            if file.endswith("_entities.json"):
                student_id = file.replace("_entities.json", "")
                try:
                    with open(os.path.join(student_kg_dir, file), 'r', encoding='utf-8') as f:
                        entities = json.load(f)
                    
                    # ç»Ÿè®¡å®ä½“ç±»å‹
                    entity_counts = defaultdict(int)
                    for entity in entities:
                        entity_type = entity.get('entity_type', 'UNKNOWN')
                        entity_counts[entity_type] += 1
                    
                    self.students[student_id] = {
                        'entities': entities,
                        'entity_counts': dict(entity_counts),
                        'total_entities': len(entities)
                    }
                    
                except Exception as e:
                    print(f"  âš ï¸ åŠ è½½å­¦ç”Ÿå¤±è´¥ {file}: {e}")
    
    def calculate_similarity_matrix(self):
        """è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ"""
        print("ğŸ”„ è®¡ç®—å­¦ç”Ÿ-é¡¹ç›®ç›¸ä¼¼åº¦çŸ©é˜µ...")
        
        if not self.projects or not self.students:
            print("âŒ æ•°æ®æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_kg_data()")
            return
        
        # åˆå§‹åŒ–çŸ©é˜µ
        student_ids = list(self.students.keys())
        project_ids = list(self.projects.keys())
        
        # åˆ›å»ºç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_matrix = np.zeros((len(student_ids), len(project_ids)))
        
        print(f"ğŸ“Š è®¡ç®— {len(student_ids)} ä¸ªå­¦ç”Ÿ Ã— {len(project_ids)} ä¸ªé¡¹ç›®çš„ç›¸ä¼¼åº¦...")
        
        for i, student_id in enumerate(student_ids):
            for j, project_id in enumerate(project_ids):
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = self._calculate_similarity(student_id, project_id)
                similarity_matrix[i, j] = similarity
                
                # ä¿å­˜è¯¦ç»†ç»“æœ
                detailed_result = self._get_detailed_similarity(student_id, project_id)
                self.detailed_results.append(detailed_result)
        
        # ä¿å­˜çŸ©é˜µ
        self.similarity_matrix = {
            'matrix': similarity_matrix.tolist(),
            'student_ids': student_ids,
            'project_ids': project_ids,
            'shape': similarity_matrix.shape
        }
        
        print(f"âœ… ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—å®Œæˆ: {similarity_matrix.shape}")
        
    def _calculate_similarity(self, student_id: str, project_id: str) -> float:
        """è®¡ç®—å•ä¸ªå­¦ç”Ÿ-é¡¹ç›®å¯¹çš„ç›¸ä¼¼åº¦"""
        if student_id not in self.students or project_id not in self.projects:
            return 0.0
        
        student_data = self.students[student_id]
        project_data = self.projects[project_id]
        
        student_entities = student_data['entity_counts']
        project_entities = project_data['entity_counts']
        
        total_similarity = 0.0
        total_weight = 0.0
        
        for entity_type, weight in self.entity_weights.items():
            student_count = student_entities.get(entity_type, 0)
            project_count = project_entities.get(entity_type, 0)
            
            if student_count > 0 or project_count > 0:
                # Jaccardç›¸ä¼¼åº¦
                intersection = min(student_count, project_count)
                union = max(student_count, project_count)
                similarity = intersection / union if union > 0 else 0.0
                
                total_similarity += similarity * weight
                total_weight += weight
        
        return total_similarity / total_weight if total_weight > 0 else 0.0
    
    def _get_detailed_similarity(self, student_id: str, project_id: str) -> SimilarityResult:
        """è·å–è¯¦ç»†çš„ç›¸ä¼¼åº¦åˆ†æ"""
        if student_id not in self.students or project_id not in self.projects:
            return SimilarityResult(
                student_id=student_id, project_id=project_id, similarity_score=0.0,
                skill_match=0.0, course_match=0.0, technology_match=0.0, major_match=0.0,
                total_entities=0, matched_entities=0
            )
        
        student_data = self.students[student_id]
        project_data = self.projects[project_id]
        
        student_entities = student_data['entity_counts']
        project_entities = project_data['entity_counts']
        
        # è®¡ç®—å„ç±»å‹åŒ¹é…åº¦
        skill_match = self._calculate_entity_match(student_entities.get('SKILL', 0), 
                                                  project_entities.get('SKILL', 0))
        course_match = self._calculate_entity_match(student_entities.get('COURSE', 0), 
                                                   project_entities.get('COURSE', 0))
        technology_match = self._calculate_entity_match(student_entities.get('TECHNOLOGY', 0), 
                                                       project_entities.get('TECHNOLOGY', 0))
        major_match = self._calculate_entity_match(student_entities.get('MAJOR', 0), 
                                                 project_entities.get('MAJOR', 0))
        
        # è®¡ç®—æ€»ä½“ç›¸ä¼¼åº¦
        total_similarity = (skill_match * 0.4 + course_match * 0.2 + 
                          technology_match * 0.3 + major_match * 0.1)
        
        # è®¡ç®—åŒ¹é…å®ä½“æ•°
        matched_entities = sum(min(student_entities.get(et, 0), project_entities.get(et, 0)) 
                              for et in self.entity_weights.keys())
        total_entities = sum(student_entities.get(et, 0) + project_entities.get(et, 0) 
                           for et in self.entity_weights.keys())
        
        return SimilarityResult(
            student_id=student_id,
            project_id=project_id,
            similarity_score=total_similarity,
            skill_match=skill_match,
            course_match=course_match,
            technology_match=technology_match,
            major_match=major_match,
            total_entities=total_entities,
            matched_entities=matched_entities
        )
    
    def _calculate_entity_match(self, student_count: int, project_count: int) -> float:
        """è®¡ç®—å®ä½“ç±»å‹åŒ¹é…åº¦"""
        if student_count == 0 and project_count == 0:
            return 1.0  # éƒ½ä¸ºç©ºï¼Œå®Œå…¨åŒ¹é…
        if student_count == 0 or project_count == 0:
            return 0.0  # ä¸€ä¸ªä¸ºç©ºï¼Œå®Œå…¨ä¸åŒ¹é…
        
        intersection = min(student_count, project_count)
        union = max(student_count, project_count)
        return intersection / union
    
    def generate_similarity_report(self):
        """ç”Ÿæˆç›¸ä¼¼åº¦æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç›¸ä¼¼åº¦æŠ¥å‘Š...")
        
        if not self.similarity_matrix:
            print("âŒ ç›¸ä¼¼åº¦çŸ©é˜µæœªè®¡ç®—ï¼Œè¯·å…ˆè°ƒç”¨ calculate_similarity_matrix()")
            return
        
        # åˆ›å»ºDataFrame
        matrix = np.array(self.similarity_matrix['matrix'])
        student_ids = self.similarity_matrix['student_ids']
        project_ids = self.similarity_matrix['project_ids']
        
        # åˆ›å»ºç›¸ä¼¼åº¦DataFrame
        similarity_df = pd.DataFrame(
            matrix, 
            index=student_ids, 
            columns=project_ids
        )
        
        # ä¿å­˜CSV
        csv_path = os.path.join(self.output_dir, "similarity_matrix.csv")
        similarity_df.to_csv(csv_path)
        print(f"ğŸ“„ ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜: {csv_path}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_statistics_report(similarity_df)
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_visualizations(similarity_df)
        
        # ç”Ÿæˆè¯¦ç»†ç»“æœ
        self._save_detailed_results()
        
    def _generate_statistics_report(self, similarity_df: pd.DataFrame):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        print("ğŸ“ˆ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        
        # åŸºæœ¬ç»Ÿè®¡
        stats = {
            'total_students': len(similarity_df.index),
            'total_projects': len(similarity_df.columns),
            'total_comparisons': similarity_df.size,
            'mean_similarity': similarity_df.values.mean(),
            'std_similarity': similarity_df.values.std(),
            'min_similarity': similarity_df.values.min(),
            'max_similarity': similarity_df.values.max(),
            'median_similarity': np.median(similarity_df.values)
        }
        
        # é«˜ç›¸ä¼¼åº¦åŒ¹é…ç»Ÿè®¡
        high_similarity_threshold = 0.7
        high_similarity_count = (similarity_df >= high_similarity_threshold).sum().sum()
        stats['high_similarity_matches'] = high_similarity_count
        stats['high_similarity_percentage'] = (high_similarity_count / similarity_df.size) * 100
        
        # æ¯ä¸ªå­¦ç”Ÿçš„æœ€ä½³åŒ¹é…
        best_matches = []
        for student_id in similarity_df.index:
            best_project = similarity_df.loc[student_id].idxmax()
            best_score = similarity_df.loc[student_id, best_project]
            best_matches.append({
                'student_id': student_id,
                'best_project': best_project,
                'best_score': best_score
            })
        
        # æ¯ä¸ªé¡¹ç›®çš„æœ€ä½³åŒ¹é…
        best_students = []
        for project_id in similarity_df.columns:
            best_student = similarity_df[project_id].idxmax()
            best_score = similarity_df.loc[best_student, project_id]
            best_students.append({
                'project_id': project_id,
                'best_student': best_student,
                'best_score': best_score
            })
        
        # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
        report = {
            'statistics': {k: float(v) if isinstance(v, (np.integer, np.floating)) else v for k, v in stats.items()},
            'best_student_matches': best_matches,
            'best_project_matches': best_students,
            'generated_at': datetime.now().isoformat()
        }
        
        report_path = os.path.join(self.output_dir, "similarity_statistics.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ“Š ç›¸ä¼¼åº¦çŸ©é˜µç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        print(f"ğŸ‘¥ å­¦ç”Ÿæ€»æ•°: {stats['total_students']}")
        print(f"ğŸ¯ é¡¹ç›®æ€»æ•°: {stats['total_projects']}")
        print(f"ğŸ”„ æ€»æ¯”è¾ƒæ¬¡æ•°: {stats['total_comparisons']}")
        print(f"ğŸ“ˆ å¹³å‡ç›¸ä¼¼åº¦: {stats['mean_similarity']:.3f}")
        print(f"ğŸ“Š ç›¸ä¼¼åº¦æ ‡å‡†å·®: {stats['std_similarity']:.3f}")
        print(f"ğŸ“‰ æœ€ä½ç›¸ä¼¼åº¦: {stats['min_similarity']:.3f}")
        print(f"ğŸ“ˆ æœ€é«˜ç›¸ä¼¼åº¦: {stats['max_similarity']:.3f}")
        print(f"ğŸ¯ é«˜ç›¸ä¼¼åº¦åŒ¹é…(â‰¥0.7): {stats['high_similarity_matches']} ({stats['high_similarity_percentage']:.1f}%)")
        print("="*60)
    
    def _generate_visualizations(self, similarity_df: pd.DataFrame):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. ç›¸ä¼¼åº¦çŸ©é˜µçƒ­åŠ›å›¾
        plt.figure(figsize=(15, 10))
        sns.heatmap(similarity_df, annot=False, cmap='YlOrRd', cbar=True)
        plt.title('å­¦ç”Ÿ-é¡¹ç›®ç›¸ä¼¼åº¦çŸ©é˜µ', fontsize=16, fontweight='bold')
        plt.xlabel('é¡¹ç›®ID', fontsize=12)
        plt.ylabel('å­¦ç”ŸID', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        heatmap_path = os.path.join(self.output_dir, "similarity_heatmap.png")
        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ”¥ çƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_path}")
        
        # 2. ç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾
        plt.figure(figsize=(10, 6))
        plt.hist(similarity_df.values.flatten(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('ç›¸ä¼¼åº¦åˆ†æ•°åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('ç›¸ä¼¼åº¦åˆ†æ•°', fontsize=12)
        plt.ylabel('é¢‘æ¬¡', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        hist_path = os.path.join(self.output_dir, "similarity_distribution.png")
        plt.savefig(hist_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š åˆ†å¸ƒå›¾å·²ä¿å­˜: {hist_path}")
        
        # 3. æ¯ä¸ªå­¦ç”Ÿçš„æœ€ä½³åŒ¹é…åˆ†æ•°
        best_scores = similarity_df.max(axis=1)
        plt.figure(figsize=(12, 6))
        best_scores.plot(kind='bar', color='lightcoral', alpha=0.7)
        plt.title('æ¯ä¸ªå­¦ç”Ÿçš„æœ€ä½³åŒ¹é…åˆ†æ•°', fontsize=14, fontweight='bold')
        plt.xlabel('å­¦ç”ŸID', fontsize=12)
        plt.ylabel('æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        best_scores_path = os.path.join(self.output_dir, "best_matches_per_student.png")
        plt.savefig(best_scores_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ† æœ€ä½³åŒ¹é…å›¾å·²ä¿å­˜: {best_scores_path}")
    
    def _save_detailed_results(self):
        """ä¿å­˜è¯¦ç»†ç»“æœ"""
        print("ğŸ’¾ ä¿å­˜è¯¦ç»†ç»“æœ...")
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        detailed_data = []
        for result in self.detailed_results:
            detailed_data.append(asdict(result))
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_path = os.path.join(self.output_dir, "detailed_similarity_results.json")
        with open(detailed_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {detailed_path}")
        
        # åˆ›å»ºTopåŒ¹é…æŠ¥å‘Š
        self._create_top_matches_report()
    
    def _create_top_matches_report(self):
        """åˆ›å»ºTopåŒ¹é…æŠ¥å‘Š"""
        print("ğŸ† åˆ›å»ºTopåŒ¹é…æŠ¥å‘Š...")
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        sorted_results = sorted(self.detailed_results, 
                               key=lambda x: x.similarity_score, reverse=True)
        
        # Top 20 åŒ¹é…
        top_20 = sorted_results[:20]
        
        # åˆ›å»ºæŠ¥å‘Š
        report = {
            'top_20_matches': [
                {
                    'rank': i+1,
                    'student_id': result.student_id,
                    'project_id': result.project_id,
                    'similarity_score': result.similarity_score,
                    'skill_match': result.skill_match,
                    'course_match': result.course_match,
                    'technology_match': result.technology_match,
                    'major_match': result.major_match,
                    'matched_entities': result.matched_entities,
                    'total_entities': result.total_entities
                }
                for i, result in enumerate(top_20)
            ],
            'generated_at': datetime.now().isoformat()
        }
        
        # ä¿å­˜TopåŒ¹é…æŠ¥å‘Š
        top_matches_path = os.path.join(self.output_dir, "top_matches_report.json")
        with open(top_matches_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ† TopåŒ¹é…æŠ¥å‘Šå·²ä¿å­˜: {top_matches_path}")
        
        # æ‰“å°Top 10
        print("\n" + "="*80)
        print("ğŸ† TOP 10 æœ€ä½³åŒ¹é…")
        print("="*80)
        for i, result in enumerate(top_20[:10], 1):
            print(f"{i:2d}. å­¦ç”Ÿ: {result.student_id} | é¡¹ç›®: {result.project_id}")
            print(f"    ç›¸ä¼¼åº¦: {result.similarity_score:.3f} | æŠ€èƒ½åŒ¹é…: {result.skill_match:.3f} | è¯¾ç¨‹åŒ¹é…: {result.course_match:.3f}")
            print(f"    æŠ€æœ¯åŒ¹é…: {result.technology_match:.3f} | ä¸“ä¸šåŒ¹é…: {result.major_match:.3f}")
            print("-" * 80)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å­¦ç”Ÿ-é¡¹ç›®ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—ç³»ç»Ÿ")
    print("="*60)
    
    # åˆ›å»ºç›¸ä¼¼åº¦è®¡ç®—å™¨
    calculator = StudentProjectSimilarityMatrix()
    
    # åŠ è½½æ•°æ®
    calculator.load_kg_data()
    
    if not calculator.projects or not calculator.students:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥çŸ¥è¯†å›¾è°±æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        return
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    calculator.calculate_similarity_matrix()
    
    # ç”ŸæˆæŠ¥å‘Š
    calculator.generate_similarity_report()
    
    print("\nâœ… ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {calculator.output_dir}")

if __name__ == "__main__":
    main()
