#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…æ´çŸ¥è¯†å›¾è°±ä¿¡æ¯æå–ä»£ç†
ä»é¡¹ç›®æè¿°(PD)å’Œå•å…ƒå¤§çº²(UO)æ„å»ºæ¸…æ´çš„çŸ¥è¯†å›¾è°±

è§„åˆ™:
1. å®ä½“: PROJECT, UNIT, SKILL/TECHNOLOGY
2. å…³ç³»: requires, teaches, belongs_to
3. çº¦æŸ: é¿å…æ˜Ÿå‹çˆ†ç‚¸ï¼Œè¿‡æ»¤æ³›åŒ–æœ¯è¯­ï¼Œåˆå¹¶åŒä¹‰è¯ï¼ŒTop-Kç›¸å…³æŠ€èƒ½
"""

import os
import json
import re
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
from typing import Dict, List, Set, Optional, Any, Tuple
from collections import defaultdict, Counter
from dataclasses import dataclass, asdict

@dataclass 
class CleanEntity:
    """æ¸…æ´å®ä½“"""
    id: str
    name: str
    entity_type: str  # PROJECT, UNIT, SKILL, TECHNOLOGY, PROGRAM
    relevance_score: float = 1.0
    properties: Dict[str, Any] = None

@dataclass
class CleanRelation:
    """æ¸…æ´å…³ç³»"""
    source_id: str
    target_id: str
    relation_type: str  # requires, teaches, belongs_to
    confidence: float = 1.0
    properties: Dict[str, Any] = None

class CleanKGExtractor:
    """æ¸…æ´çŸ¥è¯†å›¾è°±æå–å™¨"""
    
    def __init__(self):
        # åŒä¹‰è¯æ˜ å°„è¡¨
        self.skill_synonyms = {
            'machine learning': ['ml', 'machine learning', 'artificial intelligence', 'ai', 'deep learning'],
            'web development': ['web dev', 'web development', 'web programming', 'frontend', 'backend'],
            'data science': ['data science', 'data analytics', 'data analysis', 'big data'],
            'cybersecurity': ['cyber security', 'cybersecurity', 'information security', 'network security'],
            'database': ['database', 'db', 'database management', 'sql'],
            'programming': ['programming', 'coding', 'software development', 'development'],
            'networking': ['networking', 'network', 'tcp/ip', 'computer networks'],
            'cloud computing': ['cloud', 'cloud computing', 'aws', 'azure', 'gcp'],
            'mobile development': ['mobile', 'mobile dev', 'ios', 'android', 'app development'],
            'business analysis': ['business analysis', 'ba', 'business analytics', 'requirements analysis'],
            'project management': ['project management', 'pm', 'agile', 'scrum'],
            'user experience': ['ux', 'user experience', 'ui/ux', 'interface design']
        }
        
        # è¿‡æ»¤æ‰çš„æ³›åŒ–æœ¯è¯­
        self.generic_terms = {
            'computer', 'software', 'technology', 'system', 'application', 
            'development', 'programming', 'coding', 'technical', 'digital',
            'information', 'data', 'analysis', 'management', 'design'
        }
        
        # å•å…ƒä»£ç æ¨¡å¼
        self.unit_code_pattern = r'\b[A-Z]{3}\d{3}\b'
        
        # Top-K æŠ€èƒ½æ•°é‡
        self.top_k_skills = 5
        
        # ç½®ä¿¡åº¦é˜ˆå€¼
        self.confidence_threshold = 0.5
    
    def normalize_skill_name(self, skill_name: str) -> Optional[str]:
        """æ ‡å‡†åŒ–æŠ€èƒ½åç§°"""
        skill_lower = skill_name.lower().strip()
        
        # è¿‡æ»¤æ³›åŒ–æœ¯è¯­
        if skill_lower in self.generic_terms:
            return None
        
        # æ£€æŸ¥åŒä¹‰è¯æ˜ å°„
        for canonical, variants in self.skill_synonyms.items():
            if any(variant in skill_lower for variant in variants):
                return canonical
        
        # è¿‡æ»¤è¿‡çŸ­çš„æœ¯è¯­
        if len(skill_lower) < 3:
            return None
            
        return skill_lower
    
    def extract_units_from_text(self, text: str) -> List[Tuple[str, str]]:
        """ä»æ–‡æœ¬ä¸­æå–å•å…ƒä»£ç å’Œåç§°"""
        units = []
        
        # æŸ¥æ‰¾å•å…ƒä»£ç 
        unit_codes = re.findall(self.unit_code_pattern, text)
        
        for code in set(unit_codes):  # å»é‡
            # å°è¯•ä»æ–‡æœ¬ä¸­æ‰¾åˆ°å¯¹åº”çš„å•å…ƒåç§°
            pattern = rf'{code}[^\n]*'
            matches = re.findall(pattern, text)
            
            if matches:
                full_text = matches[0]
                # æå–å•å…ƒåç§°ï¼ˆå»æ‰ä»£ç éƒ¨åˆ†ï¼‰
                name_part = re.sub(rf'^{code}\s*', '', full_text).strip()
                name = name_part[:50] if name_part else f"Unit {code}"
            else:
                name = f"Unit {code}"
            
            units.append((code, name))
        
        return units
    
    def extract_skills_from_project(self, project_text: str) -> List[Tuple[str, float]]:
        """ä»é¡¹ç›®æè¿°ä¸­æå–æŠ€èƒ½å’Œç›¸å…³æ€§åˆ†æ•°"""
        skills_with_scores = []
        text_lower = project_text.lower()
        
        # åŸºäºå…³é”®è¯æƒé‡çš„æŠ€èƒ½æå–
        skill_weights = {
            'machine learning': ['machine learning', 'ml', 'deep learning', 'neural network', 'ai'],
            'web development': ['web', 'html', 'css', 'javascript', 'react', 'angular', 'vue'],
            'data science': ['data science', 'data mining', 'analytics', 'visualization', 'pandas'],
            'cybersecurity': ['security', 'encryption', 'firewall', 'vulnerability', 'attack'],
            'database': ['database', 'sql', 'mysql', 'postgresql', 'mongodb', 'nosql'],
            'networking': ['network', 'tcp/ip', 'wifi', 'routing', 'protocol'],
            'cloud computing': ['cloud', 'aws', 'azure', 'docker', 'kubernetes'],
            'mobile development': ['mobile', 'android', 'ios', 'app', 'smartphone'],
            'business analysis': ['business', 'requirements', 'stakeholder', 'process'],
            'programming': ['python', 'java', 'c++', 'programming', 'coding'],
            'project management': ['project management', 'agile', 'scrum', 'pm'],
            'user experience': ['ux', 'ui', 'user experience', 'interface', 'usability']
        }
        
        for skill, keywords in skill_weights.items():
            score = 0
            for keyword in keywords:
                if keyword in text_lower:
                    # è®¡ç®—æƒé‡ï¼šåŸºäºå…³é”®è¯å‡ºç°æ¬¡æ•°å’Œä½ç½®
                    occurrences = text_lower.count(keyword)
                    score += occurrences * (1.0 if keyword == skill else 0.5)
            
            if score > 0:
                skills_with_scores.append((skill, min(score, 5.0)))  # é™åˆ¶æœ€å¤§åˆ†æ•°
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›Top-K
        skills_with_scores.sort(key=lambda x: x[1], reverse=True)
        return skills_with_scores[:self.top_k_skills]
    
    def extract_skills_from_unit(self, unit_text: str, unit_code: str) -> List[Tuple[str, float]]:
        """ä»å•å…ƒå¤§çº²ä¸­æå–æŠ€èƒ½"""
        skills_with_scores = []
        text_lower = unit_text.lower()
        
        # åŸºäºå•å…ƒä»£ç çš„æŠ€èƒ½æ˜ å°„ï¼ˆQUTè¯¾ç¨‹ä½“ç³»ï¼‰
        unit_skill_mapping = {
            'IFN': {  # Information Technology Faculty
                'machine learning': ['machine learning', 'ml', 'data mining', 'predictive'],
                'web development': ['web', 'html', 'css', 'javascript', 'frontend'],
                'database': ['database', 'sql', 'data management', 'query'],
                'programming': ['programming', 'coding', 'algorithm', 'software'],
                'networking': ['network', 'communication', 'protocol', 'internet'],
                'cybersecurity': ['security', 'cryptography', 'protection', 'privacy'],
                'data science': ['analytics', 'statistics', 'visualization', 'insight'],
                'business analysis': ['business', 'requirements', 'process', 'analysis'],
                'project management': ['project', 'management', 'planning', 'coordination'],
                'user experience': ['user', 'interface', 'design', 'interaction']
            }
        }
        
        # è·å–å•å…ƒå‰ç¼€ï¼ˆå¦‚IFN, CABç­‰ï¼‰
        unit_prefix = unit_code[:3] if len(unit_code) >= 3 else unit_code
        
        if unit_prefix in unit_skill_mapping:
            skill_keywords = unit_skill_mapping[unit_prefix]
            
            for skill, keywords in skill_keywords.items():
                score = 0
                for keyword in keywords:
                    if keyword in text_lower:
                        occurrences = text_lower.count(keyword)
                        score += occurrences * 0.8  # å•å…ƒæŠ€èƒ½æƒé‡ç¨ä½
                
                if score > 0:
                    skills_with_scores.append((skill, min(score, 3.0)))
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›Top-K  
        skills_with_scores.sort(key=lambda x: x[1], reverse=True)
        return skills_with_scores[:self.top_k_skills]
    
    def extract_clean_kg(self, project_file: str, unit_dir: str = "unit_md") -> Tuple[List[CleanEntity], List[CleanRelation]]:
        """æå–æ¸…æ´çš„çŸ¥è¯†å›¾è°±"""
        
        entities = []
        relations = []
        
        # 1. è¯»å–é¡¹ç›®æè¿°
        with open(project_file, 'r', encoding='utf-8') as f:
            project_content = f.read()
        
        project_name = os.path.splitext(os.path.basename(project_file))[0]
        project_title = self._extract_project_title(project_content)
        
        # åˆ›å»ºé¡¹ç›®å®ä½“
        project_entity = CleanEntity(
            id=f"project_{project_name}",
            name=project_title,
            entity_type="PROJECT",
            relevance_score=1.0,
            properties={"description": project_content[:200]}
        )
        entities.append(project_entity)
        
        # 2. ä»é¡¹ç›®ä¸­æå–æŠ€èƒ½
        project_skills = self.extract_skills_from_project(project_content)
        
        for skill_name, score in project_skills:
            if score >= self.confidence_threshold:
                skill_entity = CleanEntity(
                    id=f"skill_{skill_name.replace(' ', '_')}",
                    name=skill_name,
                    entity_type="SKILL",
                    relevance_score=score,
                    properties={"source": "project"}
                )
                entities.append(skill_entity)
                
                # åˆ›å»º PROJECT â€”requiresâ†’ SKILL å…³ç³»
                relation = CleanRelation(
                    source_id=project_entity.id,
                    target_id=skill_entity.id,
                    relation_type="requires",
                    confidence=score / 5.0,  # æ ‡å‡†åŒ–åˆ°[0,1]
                    properties={"extracted_from": "project_description"}
                )
                relations.append(relation)
        
        # 3. è¯»å–å•å…ƒå¤§çº²
        unit_files = []
        if os.path.exists(unit_dir):
            unit_files = [f for f in os.listdir(unit_dir) if f.endswith('.md')]
        
        for unit_file in unit_files:
            unit_path = os.path.join(unit_dir, unit_file)
            with open(unit_path, 'r', encoding='utf-8') as f:
                unit_content = f.read()
            
            # æå–å•å…ƒä¿¡æ¯
            units_in_file = self.extract_units_from_text(unit_content)
            
            for unit_code, unit_name in units_in_file:
                # åˆ›å»ºå•å…ƒå®ä½“
                unit_entity = CleanEntity(
                    id=f"unit_{unit_code}",
                    name=f"{unit_code} {unit_name}",
                    entity_type="UNIT",
                    relevance_score=1.0,
                    properties={"code": unit_code, "full_name": unit_name}
                )
                entities.append(unit_entity)
                
                # æå–å•å…ƒæ•™æˆçš„æŠ€èƒ½
                unit_skills = self.extract_skills_from_unit(unit_content, unit_code)
                
                for skill_name, score in unit_skills:
                    if score >= self.confidence_threshold:
                        skill_id = f"skill_{skill_name.replace(' ', '_')}"
                        
                        # æ£€æŸ¥æŠ€èƒ½å®ä½“æ˜¯å¦å·²å­˜åœ¨
                        existing_skill = next((e for e in entities if e.id == skill_id), None)
                        if not existing_skill:
                            skill_entity = CleanEntity(
                                id=skill_id,
                                name=skill_name,
                                entity_type="SKILL",
                                relevance_score=score,
                                properties={"source": "unit"}
                            )
                            entities.append(skill_entity)
                        else:
                            # æ›´æ–°ç°æœ‰æŠ€èƒ½çš„ç›¸å…³æ€§åˆ†æ•°
                            existing_skill.relevance_score = max(existing_skill.relevance_score, score)
                        
                        # åˆ›å»º UNIT â€”teachesâ†’ SKILL å…³ç³»
                        relation = CleanRelation(
                            source_id=unit_entity.id,
                            target_id=skill_id,
                            relation_type="teaches",
                            confidence=score / 3.0,  # æ ‡å‡†åŒ–åˆ°[0,1]
                            properties={"unit_code": unit_code}
                        )
                        relations.append(relation)
        
        # 4. å»é‡å’Œæ¸…ç†
        entities = self._deduplicate_entities(entities)
        relations = self._filter_relations(relations, entities)
        
        return entities, relations
    
    def _extract_project_title(self, content: str) -> str:
        """æå–é¡¹ç›®æ ‡é¢˜"""
        lines = content.split('\n')
        for line in lines:
            if 'title' in line.lower() and '|' in line:
                parts = line.split('|')
                if len(parts) >= 3:
                    title = parts[-2].strip()
                    if title and len(title) > 3:
                        return title
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›ç¬¬ä¸€è¡Œéç©ºå†…å®¹
        for line in lines:
            if line.strip() and not line.startswith('#'):
                return line.strip()[:50]
        
        return "Unknown Project"
    
    def _deduplicate_entities(self, entities: List[CleanEntity]) -> List[CleanEntity]:
        """å»é‡å®ä½“"""
        seen_ids = set()
        unique_entities = []
        
        for entity in entities:
            if entity.id not in seen_ids:
                seen_ids.add(entity.id)
                unique_entities.append(entity)
        
        return unique_entities
    
    def _filter_relations(self, relations: List[CleanRelation], entities: List[CleanEntity]) -> List[CleanRelation]:
        """è¿‡æ»¤å…³ç³»"""
        entity_ids = {e.id for e in entities}
        
        valid_relations = []
        for relation in relations:
            # ç¡®ä¿å…³ç³»çš„ä¸¤ç«¯å®ä½“éƒ½å­˜åœ¨
            if relation.source_id in entity_ids and relation.target_id in entity_ids:
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦å…³ç³»
                if relation.confidence >= 0.3:
                    valid_relations.append(relation)
        
        return valid_relations
    
    def create_clean_visualization(self, entities: List[CleanEntity], relations: List[CleanRelation], 
                                 project_name: str, output_file: str):
        """åˆ›å»ºæ¸…æ´çš„çŸ¥è¯†å›¾è°±å¯è§†åŒ–"""
        
        try:
            # åˆ›å»ºNetworkXå›¾
            G = nx.DiGraph()
            
            # æ·»åŠ èŠ‚ç‚¹
            for entity in entities:
                G.add_node(entity.id, 
                          name=entity.name,
                          type=entity.entity_type,
                          score=entity.relevance_score)
            
            # æ·»åŠ è¾¹
            for relation in relations:
                G.add_edge(relation.source_id, relation.target_id,
                          relation=relation.relation_type,
                          confidence=relation.confidence)
            
            # åˆ›å»ºå¯è§†åŒ–
            plt.figure(figsize=(14, 10))
            
            # è®¡ç®—å¸ƒå±€
            pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
            
            # å®šä¹‰é¢œè‰²
            colors = {
                'PROJECT': '#FF6B6B',
                'UNIT': '#4ECDC4', 
                'SKILL': '#45B7D1',
                'TECHNOLOGY': '#96CEB4'
            }
            
            # æŒ‰ç±»å‹ç»˜åˆ¶èŠ‚ç‚¹
            for node_type, color in colors.items():
                nodes = [n for n, d in G.nodes(data=True) if d.get('type') == node_type]
                if nodes:
                    node_sizes = [1500 if node_type == 'PROJECT' 
                                else 800 if node_type == 'UNIT'
                                else 600 for _ in nodes]
                    
                    nx.draw_networkx_nodes(G, pos, nodelist=nodes,
                                         node_color=color, node_size=node_sizes,
                                         alpha=0.8, edgecolors='black', linewidths=1)
            
            # æŒ‰å…³ç³»ç±»å‹ç»˜åˆ¶è¾¹
            requires_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('relation') == 'requires']
            teaches_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('relation') == 'teaches']
            
            if requires_edges:
                nx.draw_networkx_edges(G, pos, edgelist=requires_edges,
                                     edge_color='red', width=2, alpha=0.7, arrows=True, arrowsize=15)
            
            if teaches_edges:
                nx.draw_networkx_edges(G, pos, edgelist=teaches_edges,
                                     edge_color='blue', width=2, alpha=0.7, arrows=True, arrowsize=15)
            
            # æ·»åŠ æ ‡ç­¾
            labels = {}
            for node in G.nodes():
                name = G.nodes[node].get('name', node)
                if len(name) > 20:
                    name = name[:17] + "..."
                labels[node] = name
            
            nx.draw_networkx_labels(G, pos, labels, font_size=9, font_weight='bold')
            
            # è®¾ç½®æ ‡é¢˜å’Œå›¾ä¾‹
            plt.title(f'Clean Knowledge Graph\n{project_name}', fontsize=14, fontweight='bold')
            
            # åˆ›å»ºå›¾ä¾‹
            legend_elements = [
                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['PROJECT'], 
                          markersize=15, label='PROJECT'),
                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['UNIT'], 
                          markersize=12, label='UNIT'),
                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors['SKILL'], 
                          markersize=10, label='SKILL'),
                plt.Line2D([0], [0], color='red', linewidth=2, label='requires'),
                plt.Line2D([0], [0], color='blue', linewidth=2, label='teaches')
            ]
            
            plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0, 1))
            
            plt.axis('off')
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            print(f"âœ… æ¸…æ´çŸ¥è¯†å›¾è°±å¯è§†åŒ–ç”Ÿæˆ: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            plt.close()
            return False
    
    def process_single_project(self, project_file: str, output_dir: str = None) -> bool:
        """å¤„ç†å•ä¸ªé¡¹ç›®"""
        
        project_name = os.path.splitext(os.path.basename(project_file))[0]
        print(f"\nğŸ§  å¤„ç†é¡¹ç›®: {project_name}")
        
        try:
            # æå–æ¸…æ´KG
            entities, relations = self.extract_clean_kg(project_file)
            
            print(f"  ğŸ“Š æå–ç»“æœ: {len(entities)} å®ä½“, {len(relations)} å…³ç³»")
            
            # è®¾ç½®è¾“å‡ºç›®å½•
            if not output_dir:
                output_dir = f"clean_kg_output/{project_name}"
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜å®ä½“æ•°æ®
            entities_data = [asdict(e) for e in entities]
            with open(os.path.join(output_dir, f"{project_name}_clean_entities.json"), 'w', encoding='utf-8') as f:
                json.dump(entities_data, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜å…³ç³»æ•°æ®
            relations_data = [asdict(r) for r in relations]
            with open(os.path.join(output_dir, f"{project_name}_clean_relations.json"), 'w', encoding='utf-8') as f:
                json.dump(relations_data, f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆå¯è§†åŒ–
            vis_file = os.path.join(output_dir, f"{project_name}_clean_kg.png")
            self.create_clean_visualization(entities, relations, project_name, vis_file)
            
            # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
            stats = {
                'project_name': project_name,
                'total_entities': len(entities),
                'total_relations': len(relations),
                'entity_types': Counter(e.entity_type for e in entities),
                'relation_types': Counter(r.relation_type for r in relations),
                'avg_confidence': sum(r.confidence for r in relations) / len(relations) if relations else 0,
                'top_skills': [e.name for e in sorted(entities, key=lambda x: x.relevance_score, reverse=True) 
                              if e.entity_type == 'SKILL'][:5]
            }
            
            with open(os.path.join(output_dir, f"{project_name}_clean_stats.json"), 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            
            print(f"  âœ… æ¸…æ´KGç”Ÿæˆå®Œæˆ: {output_dir}")
            return True
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            return False
    
    def process_all_projects(self, project_dir: str = "project_md"):
        """å¤„ç†æ‰€æœ‰é¡¹ç›®"""
        
        print("ğŸš€ æ¸…æ´çŸ¥è¯†å›¾è°±ä¿¡æ¯æå–ä»£ç†å¯åŠ¨...")
        print("=" * 60)
        
        if not os.path.exists(project_dir):
            print(f"âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_dir}")
            return
        
        project_files = [f for f in os.listdir(project_dir) if f.endswith('.md')]
        print(f"ğŸ“ æ‰¾åˆ° {len(project_files)} ä¸ªé¡¹ç›®æ–‡ä»¶")
        
        success_count = 0
        for i, project_file in enumerate(project_files, 1):
            project_path = os.path.join(project_dir, project_file)
            print(f"\n[{i}/{len(project_files)}] å¤„ç†: {project_file}")
            
            if self.process_single_project(project_path):
                success_count += 1
        
        print(f"\nğŸ“Š æ¸…æ´çŸ¥è¯†å›¾è°±æå–å®Œæˆ!")
        print(f"  æˆåŠŸå¤„ç†: {success_count}/{len(project_files)} ä¸ªé¡¹ç›®")
        print(f"  æˆåŠŸç‡: {success_count/len(project_files)*100:.1f}%")
        print(f"  è¾“å‡ºç›®å½•: clean_kg_output/")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  æ¸…æ´çŸ¥è¯†å›¾è°±ä¿¡æ¯æå–ä»£ç†")
    print("=" * 60)
    print("è§„åˆ™:")
    print("â€¢ å®ä½“: PROJECT, UNIT, SKILL/TECHNOLOGY") 
    print("â€¢ å…³ç³»: requires, teaches, belongs_to")
    print("â€¢ çº¦æŸ: Top-KæŠ€èƒ½, åˆå¹¶åŒä¹‰è¯, è¿‡æ»¤æ³›åŒ–æœ¯è¯­")
    print("=" * 60)
    
    extractor = CleanKGExtractor()
    extractor.process_all_projects()
    
    print("\nğŸ‰ æ¸…æ´çŸ¥è¯†å›¾è°±æå–å®Œæˆ!")

if __name__ == "__main__":
    main()





